{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning From Data Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://work.caltech.edu/homework/final.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonlinear transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathcal X \\in \\mathbb R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$z$ is a linear combination of $(1, x_1, x_2, x_1x_2, x_1^2, x_2^2, \\cdots, x_1^Q, x_2^Q)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import binom\n",
    "# We have 1, x_1, x_2.\n",
    "# How many ways are there to choose Q items?\n",
    "\n",
    "Q = 10\n",
    "total = 0\n",
    "for a in range(0, Q+1):\n",
    "    for b in range(0, Q+1):\n",
    "        for c in range(0, Q+1):\n",
    "            if b == 0 and c == 0:\n",
    "                continue\n",
    "            if a+b+c == Q:\n",
    "                total += 1\n",
    "                \n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for a in range(0, Q+1):\n",
    "    for b in range(0, Q+1):\n",
    "        if a + b <= 10 and a + b > 0:\n",
    "            total += 1\n",
    "            \n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sp\n",
    "sp.expand(sp.sympify(\"1 + x + y\")**10).__str__().count(\"+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to \"stars and bars\", this can be interpeted as the number of permutations of the string `**********||`. I.e. number of different ways to divide 10 numbers in 3 categories.\n",
    "\n",
    "We subtract 1 to account for the case where all the stars were put in the box corresponding to \"1\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = 10\n",
    "d = 2\n",
    "binom(Q + d, Q) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer: Alternative 1E, none of the above -- 65**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias and Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\bar g$ is expected value of $g^{(\\mathcal D)}$ over all data sets $\\mathcal D$. \n",
    "\n",
    "When can $\\bar g \\notin \\mathcal H$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a: All g's would be the same, and all of them in H.  \n",
    "b: g would still be in H.  \n",
    "c: g would still be in H.  \n",
    "d: g would still be in H.  \n",
    "e: Must be correct. It is nonsense that the expected value of something in H can be outside H.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:red;\"><b>Answer: Alternative 2E, none of the above.</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrong. See explanation here: http://book.caltech.edu/bookforum/showthread.php?t=4624"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected hypothesis is computed by taking an average of hypotheses. That is, e.g. (h1+h2)/2.\n",
    "\n",
    "Let A be a bad nondeterministic algorithm that always returns either h1 or h2 with equal probability.\n",
    "\n",
    "A logistic model is of the form $h(x) = \\theta(w^T x)$ where $\\theta(s) = \\frac{e^s}{1+e^s} = \\frac{1}{1 + e^{-s}}$\n",
    "\n",
    "Can we think of a case where the sum of two logistic hypotheses $h_1$ and $h_2$ cannot be written as $\\theta(s)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, imagine if h1 always has weights (0, 1) and h2 always has weights (0, -2).\n",
    "The expected model does not have weights (0, -0.5). It is not even a logistic model. See  the following plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def theta(s):\n",
    "    return 1 / (1 + np.exp(-s))\n",
    "\n",
    "def h1(x0, x1):\n",
    "    w0 = 0\n",
    "    w1 = 1\n",
    "    return theta(w0 * x0 + w1 * x1)\n",
    "\n",
    "def h2(x0, x1):\n",
    "    w0 = 0\n",
    "    w1 = -2\n",
    "    return theta(w0 * x0 + w1 * x1)\n",
    "\n",
    "xx = np.linspace(-10, 10)\n",
    "plt.plot(xx, h1(1, xx))\n",
    "plt.plot(xx, h2(1, xx))\n",
    "plt.plot(xx, 1/2 * (h1(1, xx) + h2(1, xx)))\n",
    "plt.legend([\"h1\", \"h2\", \"E[h]\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$h_3(x)$ is clearly not a logistic function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting means fitting the data more than warranted. I.e. choosing a too complex model for the amount of data. Fitting to the noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a: If there is overfitting, there must be two or more hypotheses that have different values of E_in. -- True. We have chosen a too complex model that fits the input data too well, and in order to do that we had to compare multiple models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b: If there is overfitting, there must be two or more hypotheses that have different values of E_out. -- True. If all hypotheses were equally good, we cannot really call this overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c: If there is overfitting, there must be two or more hypotheses that have different values of (E_out - E_in). -- ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d: We can always determine if there is overfitting by comparing the values of E_out - E_in. -- ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e: We cannot determine overfitting based on one hypothesis only. -- True."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deterministic noise is the error due to complexity in the target function that our model cannot approximate.\n",
    "\n",
    "Thus deterministic noise depends on our hypothesis set.\n",
    "\n",
    "**Answer: Alternative 4D: Stochastic noise does not depend on the hypothesis set.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The least squares linear regression solution satisfies the constraint. Thus the regularization has no effect, and w_reg = w_lin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer: Alternative A**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer: Alternative B -- soft-order constraints can be translated into augmented error**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = np.loadtxt(\"features.train\")\n",
    "data_test = np.loadtxt(\"features.test\")\n",
    "y_train, X_train = data_train[:, :1], data_train[:, 1:]\n",
    "y_test, X_test = data_test[:, :1], data_test[:, 1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I already implemented regularized least squares regression in the previous homework, I will use sklearn here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> from sklearn.linear_model import Ridge  \n",
    "Minimizes the objective function:  \n",
    "||y - Xw||^2_2 + alpha * ||w||^2_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "def get_n_vs_m_dataset(ns, ms, which):\n",
    "    if which == \"train\":\n",
    "        data = data_train.copy()\n",
    "    elif which == \"test\":\n",
    "        data = data_test.copy()\n",
    "    else:\n",
    "        1/0\n",
    "    in_ns = np.isin(data[:,0], ns)\n",
    "    in_ms = np.isin(data[:,0], ms)\n",
    "    in_either = np.logical_or(in_ns, in_ms)\n",
    "    data[in_ns,0] = +1.0\n",
    "    data[in_ms,0] = -1.0\n",
    "    X, y = data[in_either,1:], data[in_either,0]\n",
    "    return np.hstack([np.ones([X.shape[0], 1]), X]), y\n",
    "    \n",
    "X, y = get_n_vs_m_dataset([5], [0, 1, 2, 3, 4, 6, 7, 8, 9], \"train\")\n",
    "\n",
    "\n",
    "def plot(X, y):\n",
    "    above = np.where(y > 0)\n",
    "    below = np.where(y < 0)\n",
    "    plt.scatter(X[below,1], X[below,2], s=1)\n",
    "    plt.scatter(X[above,1], X[above,2], s=1)\n",
    "    plt.legend([\"ms\", \"ns\"])\n",
    "    plt.xlabel(\"Intensity\")\n",
    "    plt.ylabel(\"Symmetry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_decision_boundary(clf):\n",
    "    N = 1000\n",
    "    X = np.zeros((N,3))\n",
    "    X[:,0] = 1\n",
    "    X[:,1] = 2*np.random.rand(N) - 1\n",
    "    X[:,2] = np.random.rand(N)*(-14) + 7\n",
    "    y = clf.predict(X)\n",
    "    plot(X, y)\n",
    "\n",
    "def in_sample_error(ns, ms):\n",
    "    X, y = get_n_vs_m_dataset(ns, ms, \"train\")\n",
    "    Z = X # = (1, x1, x2)\n",
    "    clf = RidgeClassifier(alpha=1.0, fit_intercept=False)\n",
    "    clf.fit(Z, y)\n",
    "    plot_decision_boundary(clf)\n",
    "    plot(X, y)\n",
    "    plt.show()\n",
    "    return np.mean(clf.predict(Z) != y)\n",
    "    \n",
    "print(in_sample_error([5], [0, 1, 2, 3, 4, 6, 7, 8, 9]))\n",
    "print(in_sample_error([6], [0, 1, 2, 3, 4, 5, 7, 8, 9]))\n",
    "print(in_sample_error([7], [0, 1, 2, 3, 4, 5, 6, 8, 9]))\n",
    "print(in_sample_error([8], [0, 1, 2, 3, 4, 5, 6, 7, 9]))\n",
    "print(in_sample_error([9], [0, 1, 2, 3, 4, 5, 6, 7, 8]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the classifiers are horrible, but 8 vs all has the lowest E_in.\n",
    "This is since the training the estimator always guesses -1, and this one coincidentally has fewer of that that class compared to other numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternative 7D: 8 vs all**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary2(clf, phi):\n",
    "    N = 1000\n",
    "    X = np.zeros((N,3))\n",
    "    X[:,0] = 1\n",
    "    X[:,1] = 2*np.random.rand(N) - 1\n",
    "    X[:,2] = np.random.rand(N)*(-14) + 7\n",
    "    y = clf.predict(phi(X))\n",
    "    plot(X, y)\n",
    "\n",
    "def phi(X):\n",
    "    Z = np.zeros((X.shape[0], 6))\n",
    "    Z[:,0] = 1\n",
    "    Z[:,1] = X[:,1]\n",
    "    Z[:,2] = X[:,2]\n",
    "    Z[:,3] = X[:,1]*X[:,2]\n",
    "    Z[:,4] = X[:,1]**2\n",
    "    Z[:,5] = X[:,2]**2\n",
    "    return Z\n",
    "\n",
    "def out_of_sample_error(ns, ms):\n",
    "    X_train, y_train = get_n_vs_m_dataset(ns, ms, \"train\")\n",
    "    X_test, y_test = get_n_vs_m_dataset(ns, ms, \"test\")\n",
    "    \n",
    "    Z_train = phi(X_train)\n",
    "    Z_test = phi(X_test)\n",
    "\n",
    "    clf = RidgeClassifier(alpha=1, fit_intercept=False)\n",
    "    clf.fit(Z_train, y_train)\n",
    "    plot_decision_boundary2(clf, phi)\n",
    "    plot(X_train, y_train)\n",
    "    plt.show()\n",
    "    return np.mean(clf.predict(Z_test) != y_test)\n",
    "    \n",
    "print(\"0 vs all Eout\", out_of_sample_error([0], [1, 2, 3, 4, 5, 6, 7, 8, 9]))\n",
    "print(\"1 vs all Eout\", out_of_sample_error([1], [0, 2, 3, 4, 5, 6, 7, 8, 9]))\n",
    "print(\"2 vs all Eout\", out_of_sample_error([2], [0, 1, 3, 4, 5, 6, 7, 8, 9]))\n",
    "print(\"3 vs all Eout\", out_of_sample_error([3], [0, 1, 2, 4, 5, 6, 7, 8, 9]))\n",
    "print(\"4 vs all Eout\", out_of_sample_error([4], [0, 1, 2, 3, 5, 6, 7, 8, 9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little gotcha here: The intercept is not penalized for sklearn's Ridge method when using fit_intercept=True.\n",
    "So instead add a ones column and set fit_intercept=False to get the desired behavior of also penalizing the intercept term w0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternative 8B: 1 vs all has the lowest E_out**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_all(ns, ms):\n",
    "    print(\"{} vs all\".format(ns[0]))\n",
    "    X_train, y_train = get_n_vs_m_dataset(ns, ms, \"train\")\n",
    "    X_test, y_test = get_n_vs_m_dataset(ns, ms, \"test\")\n",
    "    \n",
    "    Z_train = phi(X_train)\n",
    "    Z_test = phi(X_test)\n",
    "    \n",
    "    clf = RidgeClassifier(alpha=1, fit_intercept=False)\n",
    "\n",
    "    # No transform E_in\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"  No transform E_in\\t\", np.mean(clf.predict(X_train) != y_train))\n",
    "    # No transform E_out\n",
    "    print(\"  No transform E_out\\t\", np.mean(clf.predict(X_test) != y_test))\n",
    "    # Transform E_in\n",
    "    clf.fit(Z_train, y_train)\n",
    "    print(\"     Transform E_in\\t\", np.mean(clf.predict(Z_train) != y_train))\n",
    "    # Transform E_out\n",
    "    print(\"     Transform E_out\\t\", np.mean(clf.predict(Z_test) != y_test))\n",
    "\n",
    "check_all([1], [0, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "check_all([2], [0, 1, 3, 4, 5, 6, 7, 8, 9])\n",
    "check_all([3], [0, 1, 2, 4, 5, 6, 7, 8, 9])\n",
    "check_all([4], [0, 1, 2, 3, 5, 6, 7, 8, 9])\n",
    "check_all([5], [0, 1, 2, 3, 4, 6, 7, 8, 9])\n",
    "check_all([6], [0, 1, 2, 3, 4, 5, 7, 8, 9])\n",
    "check_all([7], [0, 1, 2, 3, 4, 5, 6, 8, 9])\n",
    "check_all([8], [0, 1, 2, 3, 4, 5, 6, 7, 9])\n",
    "check_all([9], [0, 1, 2, 3, 4, 5, 6, 7, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a: False. Doesn't look like overfitting to me.  \n",
    "b: False: No, transform doesn't improve E_out  \n",
    "c: False: There is a slight difference in out of sample performance. E.g. 5 vs all is _slightly_ better.  \n",
    "d: False: The transform sometimes sometimes has the same out of sample performance.  \n",
    "e: True: The performance is improved, but only by a small percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_vs_all_improvement_percentage = -(0.07922272047832586 - 0.07972097658196313)/0.07972097658196313\n",
    "print(five_vs_all_improvement_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternative 9E**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = [5]\n",
    "ms = [1]\n",
    "print(\"1 vs 5\")\n",
    "\n",
    "X_train, y_train = get_n_vs_m_dataset(ns, ms, \"train\")\n",
    "X_test, y_test = get_n_vs_m_dataset(ns, ms, \"test\")\n",
    "\n",
    "Z_train = phi(X_train)\n",
    "Z_test = phi(X_test)\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "\n",
    "print(\"lambda=1\")\n",
    "clf = RidgeClassifier(alpha=1, fit_intercept=False)\n",
    "\n",
    "# Transform E_in\n",
    "clf.fit(Z_train, y_train)\n",
    "print(\"     Transform E_in\\t\", np.mean(clf.predict(Z_train) != y_train))\n",
    "# Transform E_out\n",
    "print(\"     Transform E_out\\t\", np.mean(clf.predict(Z_test) != y_test))\n",
    "\n",
    "\n",
    "plot_decision_boundary2(clf, phi)\n",
    "plot(X_train, y_train)\n",
    "plt.title(\"Training data\")\n",
    "plt.show()\n",
    "\n",
    "plot_decision_boundary2(clf, phi)\n",
    "plot(X_test, y_test)\n",
    "plt.title(\"Test data\")\n",
    "plt.show()\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "print(\"lambda=0.01\")\n",
    "clf2 = RidgeClassifier(alpha=0.01, fit_intercept=False)\n",
    "\n",
    "# Transform E_in\n",
    "clf2.fit(Z_train, y_train)\n",
    "print(\"     Transform E_in\\t\", np.mean(clf2.predict(Z_train) != y_train))\n",
    "# Transform E_out\n",
    "print(\"     Transform E_out\\t\", np.mean(clf2.predict(Z_test) != y_test))\n",
    "\n",
    "plot_decision_boundary2(clf2, phi)\n",
    "plot(X_train, y_train)\n",
    "plt.title(\"Training data\")\n",
    "plt.show()\n",
    "\n",
    "plot_decision_boundary2(clf2, phi)\n",
    "plot(X_test, y_test)\n",
    "plt.title(\"Test data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another gotcha: RidgeRegression in sklearn doesn't work properly with solver=\"lsqr\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anyways looks like we have overfitting, since E_in goes slightly down and E_out goes slightly up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternative 10A: Overfitting occurs**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
